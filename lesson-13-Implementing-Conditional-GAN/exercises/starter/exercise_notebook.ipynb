{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3728cb61",
   "metadata": {},
   "source": [
    "## Part 0: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae37306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import cGAN from demo folder\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(\".\"), \"Demo\"))\n",
    "from models.cgan import create_cgan_models\n",
    "from cgan_training import ConditionalGANTrainer, initialize_weights\n",
    "\n",
    "# CIFAR-10 class names\n",
    "CIFAR10_CLASSES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Determine device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb59bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers \n",
    "def plot_loss_curves_cgan(results):\n",
    "    \"\"\"Plot discriminator and generator losses for cGAN.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    d_losses = np.array(results[\"d_losses\"])\n",
    "    g_losses = np.array(results[\"g_losses\"])\n",
    "\n",
    "    # Plot D loss\n",
    "    axes[0].plot(d_losses, linewidth=2, color=\"navy\", label=\"D Loss\")\n",
    "    axes[0].axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "    axes[0].set_xlabel(\"Training Step\", fontsize=11)\n",
    "    axes[0].set_ylabel(\"BCE Loss\", fontsize=11)\n",
    "    axes[0].set_title(\n",
    "        \"Discriminator Loss Over Training\", fontsize=12, fontweight=\"bold\"\n",
    "    )\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot G loss\n",
    "    axes[1].plot(g_losses, linewidth=2, color=\"darkgreen\", label=\"G Loss\")\n",
    "    axes[1].set_xlabel(\"Training Step\", fontsize=11)\n",
    "    axes[1].set_ylabel(\"BCE Loss\", fontsize=11)\n",
    "    axes[1].set_title(\"Generator Loss Over Training\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"D Loss - Mean: {d_losses.mean():.4f}, Std: {d_losses.std():.4f}\")\n",
    "    print(f\"G Loss - Mean: {g_losses.mean():.4f}, Std: {g_losses.std():.4f}\")\n",
    "\n",
    "\n",
    "def visualize_class_grid(grid_images, class_names, title=\"cGAN Class Disentanglement\"):\n",
    "    \"\"\"Visualize 10x10 class disentanglement grid.\"\"\"\n",
    "    grid_images_cpu = (grid_images.cpu() + 1) / 2\n",
    "    grid_images_cpu = torch.clamp(grid_images_cpu, 0, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(16, 16))\n",
    "\n",
    "    for class_id in range(10):\n",
    "        for sample_id in range(10):\n",
    "            idx = class_id * 10 + sample_id\n",
    "            ax = axes[class_id, sample_id]\n",
    "            img = grid_images_cpu[idx].cpu().permute(1, 2, 0).numpy()\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "            if sample_id == 0:\n",
    "                ax.set_ylabel(class_names[class_id], fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"{title}\\n(Rows: Classes | Columns: Same Noise, Different Classes)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_class_samples(class_samples, class_name, title=\"Generated Samples\"):\n",
    "    \"\"\"Visualize 16 samples from a specific class.\"\"\"\n",
    "    class_samples_cpu = (class_samples.cpu() + 1) / 2\n",
    "    class_samples_cpu = torch.clamp(class_samples_cpu, 0, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "\n",
    "    for i in range(16):\n",
    "        ax = axes[i // 8, i % 8]\n",
    "        img = class_samples_cpu[i].cpu().permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f'16 Generated Samples from Class \"{class_name}\"',\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\" Visualization helpers loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76141771",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Load CIFAR-10 Dataset\n",
    "\n",
    "**TODO:** Load the CIFAR-10 dataset with appropriate transforms.\n",
    "\n",
    "**Requirements:**\n",
    "- Normalize images to [-1, 1] range (using mean=0.5, std=0.5)\n",
    "- Create DataLoader with batch_size=64\n",
    "- Enable shuffling for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ab5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Load CIFAR-10 dataset with transforms\n",
    "# Step 1a: Define transforms (ToTensor + Normalize to [-1, 1])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # YOUR CODE HERE: Add ToTensor()\n",
    "        # YOUR CODE HERE: Add Normalize with mean=0.5, std=0.5 for each channel\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 1b: Load training dataset\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Step 1c: Create DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    # YOUR CODE HERE: Pass dataset and batch size\n",
    "    # YOUR CODE HERE: Enable shuffling\n",
    "    num_workers=0,  # MPS compatibility\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(train_dataset)} training images\")\n",
    "print(f\"DataLoader: {len(train_loader)} batches of size {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8d06a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Create cGAN Models\n",
    "\n",
    "**TODO:** Create the conditional generator and discriminator.\n",
    "\n",
    "**Requirements:**\n",
    "- Use `create_cgan_models()` function\n",
    "- Set latent_dim=100 (noise vector dimension)\n",
    "- Set num_classes=10 (CIFAR-10 has 10 classes)\n",
    "- Initialize weights using DCGAN guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Create cGAN models\n",
    "latent_dim = 100\n",
    "num_classes = 10\n",
    "label_dim = 50  # Label embedding dimension\n",
    "\n",
    "# Step 2a: Create generator and discriminator\n",
    "generator, discriminator = create_cgan_models(\n",
    "    # YOUR CODE HERE: Pass latent_dim\n",
    "    # YOUR CODE HERE: Pass num_classes\n",
    "    # YOUR CODE HERE: Pass label_dim\n",
    "    num_channels=3,\n",
    "    # YOUR CODE HERE: Pass device\n",
    ")\n",
    "\n",
    "# Step 2b: Initialize weights\n",
    "initialize_weights(generator)\n",
    "initialize_weights(discriminator)\n",
    "\n",
    "# Verify model parameters\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(\n",
    "    f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56a8ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Create Trainer\n",
    "\n",
    "**TODO:** Instantiate the ConditionalGANTrainer.\n",
    "\n",
    "**Requirements:**\n",
    "- Pass generator and discriminator\n",
    "- Set lr_g=0.0002 (Generator learning rate)\n",
    "- Set lr_d=0.0002 (Discriminator learning rate)\n",
    "- Use Adam optimizer with beta1=0.5, beta2=0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: Create trainer\n",
    "trainer = ConditionalGANTrainer(\n",
    "    # YOUR CODE HERE: Pass generator\n",
    "    # YOUR CODE HERE: Pass discriminator\n",
    "    # YOUR CODE HERE: Pass device\n",
    "    lr_g=0.0002,\n",
    "    lr_d=0.0002,\n",
    "    beta1=0.5,\n",
    "    beta2=0.999,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully\")\n",
    "print(f\"Learning rates - G: 0.0002, D: 0.0002\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d4991",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Train the cGAN\n",
    "\n",
    "**TODO:** Train the model for 20 epochs.\n",
    "\n",
    "**Requirements:**\n",
    "- Use trainer.train() method\n",
    "- Set num_epochs=20\n",
    "- Pass latent_dim and num_classes\n",
    "- Log progress every 50 batches\n",
    "\n",
    "**Note:** This will take 20-30 minutes on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ed2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Train the cGAN\n",
    "num_epochs = 20\n",
    "\n",
    "print(f\"Training cGAN for {num_epochs} epochs...\")\n",
    "print(\"This will take 20-30 minutes on GPU\\n\")\n",
    "\n",
    "results = trainer.train(\n",
    "    # YOUR CODE HERE: Pass train_loader\n",
    "    # YOUR CODE HERE: Pass num_epochs\n",
    "    # YOUR CODE HERE: Pass latent_dim\n",
    "    # YOUR CODE HERE: Pass num_classes\n",
    "    log_interval=50,\n",
    ")\n",
    "\n",
    "print(f\"\\n Training complete after {num_epochs} epochs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f137797",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Plot Loss Curves\n",
    "\n",
    "**TODO:** Visualize Generator and Discriminator losses during training.\n",
    "\n",
    "**Requirements:**\n",
    "- Create 1×2 subplot (D loss, G loss)\n",
    "- Plot results['d_losses'] and results['g_losses']\n",
    "- Add labels and titles\n",
    "- Add reference line at y=0.5 (ideal discriminator loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Plot loss curves\n",
    "plot_loss_curves_cgan(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539edc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Generate 10×10 Class Disentanglement Grid\n",
    "\n",
    "**TODO:** Generate a 10×10 grid showing all classes with the same noise vector.\n",
    "\n",
    "**Requirements:**\n",
    "- Use trainer.generate_all_classes_grid()\n",
    "- Generate 10 classes × 10 samples per class = 100 images\n",
    "- Same noise z, different class labels y\n",
    "- Denormalize from [-1,1] to [0,1]\n",
    "- Visualize as 10×10 subplot grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bd5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6: Generate 10x10 class disentanglement grid\n",
    "print(\"Generating 10×10 class disentanglement grid...\")\n",
    "\n",
    "# Step 6a: Generate grid\n",
    "grid_images = trainer.generate_all_classes_grid(\n",
    "    # YOUR CODE HERE: Pass num_classes=10\n",
    "    # YOUR CODE HERE: Pass samples_per_class=10\n",
    "    # YOUR CODE HERE: Pass latent_dim\n",
    "    shared_z=None,\n",
    ")\n",
    "\n",
    "# Step 6b: Visualize using helper\n",
    "visualize_class_grid(\n",
    "    grid_images, CIFAR10_CLASSES, title=\"cGAN Class Disentanglement: 10×10 Grid\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Grid generated: {grid_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487bc60b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Generate Single-Class Samples\n",
    "\n",
    "**TODO:** Generate 16 images of a specific class (e.g., dogs).\n",
    "\n",
    "**Requirements:**\n",
    "- Use trainer.generate_class_samples()\n",
    "- Set target_class=5 (dogs)\n",
    "- Generate num_samples=16\n",
    "- Denormalize to [0,1]\n",
    "- Display as 2×8 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 7: Generate single-class samples\n",
    "target_class = 5  # dogs\n",
    "\n",
    "print(f\"Generating 16 samples of class '{CIFAR10_CLASSES[target_class]}'...\")\n",
    "\n",
    "# Step 7a: Generate samples\n",
    "class_samples = trainer.generate_class_samples(\n",
    "    # YOUR CODE HERE: Pass target_class\n",
    "    # YOUR CODE HERE: Pass num_samples=16\n",
    "    # YOUR CODE HERE: Pass latent_dim\n",
    ")\n",
    "\n",
    "# Step 7b: Visualize using helper\n",
    "visualize_class_samples(class_samples, CIFAR10_CLASSES[target_class])\n",
    "\n",
    "print(\n",
    "    f\"✓ Generated 16 samples from class {CIFAR10_CLASSES[target_class]} (class {target_class})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a7f62f",
   "metadata": {},
   "source": [
    "\n",
    "## Part 8: Analyze Class Disentanglement Quality\n",
    "\n",
    "**TODO:** Answer the following questions about the cGAN's class disentanglement.\n",
    "\n",
    "**Analysis Questions:**\n",
    "\n",
    "1. **Within-Row Variation:** Looking at the 10×10 grid, do images in the same row (same class) show style variation? What causes this variation?\n",
    "\n",
    "2. **Across-Row Differences:** Are rows clearly different from each other? Can you easily tell which row is dogs vs cars just by looking?\n",
    "\n",
    "3. **Class Control:** Do the class labels seem to have a strong effect on the generated images? How can you tell?\n",
    "\n",
    "4. **Quality Issues:** Do any rows look wrong or blurry? Which classes are generated most successfully?\n",
    "\n",
    "5. **Data Augmentation:** Would you use these generated images to augment a training dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a5a68",
   "metadata": {},
   "source": [
    "## Part 8 Analysis: Your Answers\n",
    "\n",
    "**Question 1: Within-Row Variation**\n",
    "```\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "**Question 2: Across-Row Differences**\n",
    "```\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "**Question 3: Class Control**\n",
    "```\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "**Question 4: Quality Issues**\n",
    "```\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "**Question 5: Data Augmentation**\n",
    "```\n",
    "YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9e884",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Compare Generated vs Real Images (Optional)\n",
    "\n",
    "**TODO:** Create side-by-side comparison of generated vs real images for each class.\n",
    "\n",
    "**Requirements:**\n",
    "- Generate one image per class\n",
    "- Find one real image per class from dataset\n",
    "- Display as 3 rows × 10 columns\n",
    "- Row 1: Generated, Row 2: Real, Row 3: Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9 (Optional): Compare generated vs real images\n",
    "print(\"Generating comparison grid...\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 10, figsize=(18, 6))\n",
    "\n",
    "for class_id in range(10):\n",
    "    # Step 9a: Generate image for this class\n",
    "    generated = trainer.generate_class_samples(\n",
    "        # YOUR CODE HERE: Pass target_class=class_id\n",
    "        # YOUR CODE HERE: Pass num_samples=1\n",
    "        # YOUR CODE HERE: Pass latent_dim\n",
    "    )\n",
    "    generated_denorm = (generated.cpu() + 1) / 2\n",
    "    generated_denorm = torch.clamp(generated_denorm, 0, 1)\n",
    "\n",
    "    # Step 9b: Find real image for this class\n",
    "    # YOUR CODE HERE: Find index of first image with class_id in train_dataset.targets\n",
    "    idx = None  # YOUR CODE HERE\n",
    "    real_img = (train_dataset[idx][0] + 1) / 2\n",
    "\n",
    "    # Step 9c: Display generated image\n",
    "    ax = axes[0, class_id]\n",
    "    # YOUR CODE HERE: Display generated image\n",
    "    ax.set_title(f\"{CIFAR10_CLASSES[class_id]}\", fontsize=9)\n",
    "    ax.axis(\"off\")\n",
    "    if class_id == 0:\n",
    "        ax.text(\n",
    "            -0.3,\n",
    "            0.5,\n",
    "            \"Generated\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    # Step 9d: Display real image\n",
    "    ax = axes[1, class_id]\n",
    "    # YOUR CODE HERE: Display real image\n",
    "    ax.axis(\"off\")\n",
    "    if class_id == 0:\n",
    "        ax.text(\n",
    "            -0.3,\n",
    "            0.5,\n",
    "            \"Real\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    # Step 9e: Add quality assessment\n",
    "    ax = axes[2, class_id]\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        0.5,\n",
    "        f\"Quality:\\nGood✓\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=8,\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"lightgreen\", alpha=0.7),\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "    if class_id == 0:\n",
    "        ax.text(\n",
    "            -0.3,\n",
    "            0.5,\n",
    "            \"Assessment\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            fontweight=\"bold\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "plt.suptitle(\"Generated vs Real Images (One per Class)\", fontsize=13, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\" Comparison complete\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4df9f6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    " **Conditional GANs:** How to add class information to Generator and Discriminator\n",
    "\n",
    " **Label Conditioning:** Early concatenation (G) vs late concatenation (D)\n",
    "\n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Conditioning enables control:** cGANs let you generate specific classes on demand\n",
    "\n",
    "2. **Disentanglement matters:** Good separation of class from style is crucial for quality\n",
    "\n",
    "3. **Grid visualization is powerful:** The 10×10 grid clearly shows whether class labels work\n",
    "\n",
    "4. **Practical uses:** Generate synthetic data for underrepresented classes, augment datasets\n",
    "\n",
    "### Next Steps to Improve\n",
    "\n",
    "+ Train for more epochs (50+) for better quality\n",
    "+ Try different architectures (spectral norm, progressive training)\n",
    "+ Compute metrics (FID, IS) for quantitative evaluation\n",
    "+ Use generated images to train a classifier and measure improvement\n",
    "+ Experiment with CIFAR-100 or ImageNet subsets\n",
    "+ Compare with other conditional architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f727cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
