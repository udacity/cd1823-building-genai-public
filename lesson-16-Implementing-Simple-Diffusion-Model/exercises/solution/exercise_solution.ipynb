{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b795d6",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93014f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from typing import Tuple, Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910b7d9",
   "metadata": {},
   "source": [
    "## Solution 1: Complete NoiseScheduler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf66d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseScheduler:\n",
    "    \"\"\"\n",
    "    Fixed variance schedule for forward diffusion process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        \"\"\"\n",
    "        Initialize noise scheduler with linear beta schedule.\n",
    "        \"\"\"\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # Create linear beta schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "\n",
    "        # Compute alphas and cumulative products\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.ones(1), self.alphas_cumprod[:-1]])\n",
    "\n",
    "        # Pre-compute useful quantities\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "\n",
    "    def get_coefficients(self, timestep):\n",
    "        \"\"\"\n",
    "        Get forward diffusion coefficients for timestep(s).\n",
    "        \"\"\"\n",
    "        device = timestep.device\n",
    "        sqrt_alphas_cumprod = self.sqrt_alphas_cumprod.to(device)[timestep]\n",
    "        sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod.to(device)[\n",
    "            timestep\n",
    "        ]\n",
    "\n",
    "        # Reshape to (batch, 1, 1, 1) for broadcasting with images\n",
    "        sqrt_alphas_cumprod = sqrt_alphas_cumprod.reshape(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod.reshape(\n",
    "            -1, 1, 1, 1\n",
    "        )\n",
    "\n",
    "        return sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e2335",
   "metadata": {},
   "source": [
    "## Solution 2: Forward Diffusion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x_0, timestep, scheduler, noise=None):\n",
    "    \"\"\"\n",
    "    Forward diffusion: Add noise to image at timestep t.\n",
    "\n",
    "    Formula: x_t = sqrt(ᾱ_t) * x_0 + sqrt(1 - ᾱ_t) * ε\n",
    "    \"\"\"\n",
    "    # Sample random noise if not provided\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "\n",
    "    # Get coefficients from scheduler\n",
    "    sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod = scheduler.get_coefficients(\n",
    "        timestep\n",
    "    )\n",
    "\n",
    "    # Apply forward diffusion formula\n",
    "    x_t = sqrt_alphas_cumprod * x_0 + sqrt_one_minus_alphas_cumprod * noise\n",
    "\n",
    "    return x_t, noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6ff56",
   "metadata": {},
   "source": [
    "## Solution 3: TimeEmbedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Sinusoidal time embedding for timestep conditioning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, timestep):\n",
    "        \"\"\"\n",
    "        Convert timestep to embedding using sinusoidal functions.\n",
    "        \"\"\"\n",
    "        device = timestep.device\n",
    "        half_dim = self.embedding_dim // 2\n",
    "\n",
    "        # Create frequency schedule\n",
    "        freqs = torch.exp(\n",
    "            -math.log(10000) * torch.arange(half_dim, device=device) / half_dim\n",
    "        )\n",
    "\n",
    "        # Multiply timestep by frequencies\n",
    "        args = timestep[:, None].float() * freqs[None, :]\n",
    "\n",
    "        # Apply sine and cosine and concatenate\n",
    "        embedding = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ca2c4",
   "metadata": {},
   "source": [
    "## Solution 4: ResidualBlock with Time Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e138225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with timestep conditioning using FiLM (Feature-wise Linear Modulation).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, time_embedding_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm1 = nn.GroupNorm(num_groups=32, num_channels=in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.norm2 = nn.GroupNorm(num_groups=32, num_channels=out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        # Time conditioning MLP (FiLM)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_embedding_dim, out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.skip = nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_embedding):\n",
    "        \"\"\"\n",
    "        Forward pass with time conditioning via FiLM.\n",
    "        \"\"\"\n",
    "        # First path with time conditioning\n",
    "        h = self.norm1(x)\n",
    "        h = F.silu(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        # Apply time conditioning via FiLM (modulate by time)\n",
    "        time_scale_shift = self.time_mlp(time_embedding)[:, :, None, None]\n",
    "        h = h * time_scale_shift\n",
    "\n",
    "        # Second path\n",
    "        h = self.norm2(h)\n",
    "        h = F.silu(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        # Add skip connection\n",
    "        return h + self.skip(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea754383",
   "metadata": {},
   "source": [
    "## Solution 5: SimpleUNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple U-Net for MNIST noise prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_channels=1, base_channels=64, time_embedding_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_embedding = TimeEmbedding(time_embedding_dim)\n",
    "\n",
    "        # Initial conv\n",
    "        self.init_conv = nn.Conv2d(\n",
    "            image_channels, base_channels, kernel_size=3, padding=1\n",
    "        )\n",
    "\n",
    "        # Encoder (downsampling)\n",
    "        self.down_conv1 = nn.Conv2d(\n",
    "            base_channels, base_channels, kernel_size=4, stride=2, padding=1\n",
    "        )\n",
    "        self.down_res1 = ResidualBlock(\n",
    "            base_channels, base_channels * 2, time_embedding_dim\n",
    "        )\n",
    "\n",
    "        self.down_conv2 = nn.Conv2d(\n",
    "            base_channels * 2, base_channels * 2, kernel_size=4, stride=2, padding=1\n",
    "        )\n",
    "        self.down_res2 = ResidualBlock(\n",
    "            base_channels * 2, base_channels * 2, time_embedding_dim\n",
    "        )\n",
    "\n",
    "        # Middle (bottleneck)\n",
    "        self.middle_res = ResidualBlock(\n",
    "            base_channels * 2, base_channels * 2, time_embedding_dim\n",
    "        )\n",
    "\n",
    "        # Decoder (upsampling)\n",
    "        self.up_conv2 = nn.ConvTranspose2d(\n",
    "            base_channels * 2, base_channels * 2, kernel_size=4, stride=2, padding=1\n",
    "        )\n",
    "        self.up_res2 = ResidualBlock(\n",
    "            base_channels * 2, base_channels, time_embedding_dim\n",
    "        )\n",
    "\n",
    "        self.up_conv1 = nn.ConvTranspose2d(\n",
    "            base_channels, base_channels, kernel_size=4, stride=2, padding=1\n",
    "        )\n",
    "        self.up_res1 = ResidualBlock(base_channels, base_channels, time_embedding_dim)\n",
    "\n",
    "        # Final output\n",
    "        self.final_norm = nn.GroupNorm(num_groups=32, num_channels=base_channels)\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            base_channels, image_channels, kernel_size=3, padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, timestep):\n",
    "        \"\"\"\n",
    "        Predict noise given noisy image and timestep.\n",
    "        \"\"\"\n",
    "        # Create time embedding\n",
    "        time_emb = self.time_embedding(timestep)\n",
    "\n",
    "        # Initial conv\n",
    "        h = self.init_conv(x)\n",
    "\n",
    "        # Encoder (downsampling: 28x28 → 14x14 → 7x7)\n",
    "        h_down1 = self.down_res1(h, time_emb)\n",
    "        h = self.down_conv1(h_down1)\n",
    "\n",
    "        h_down2 = self.down_res2(h, time_emb)\n",
    "        h = self.down_conv2(h_down2)\n",
    "\n",
    "        # Middle (bottleneck at 7x7)\n",
    "        h = self.middle_res(h, time_emb)\n",
    "\n",
    "        # Decoder (upsampling: 7x7 → 14x14 → 28x28)\n",
    "        h = self.up_conv2(h)\n",
    "        h = self.up_res2(h, time_emb)\n",
    "\n",
    "        h = self.up_conv1(h)\n",
    "        h = self.up_res1(h, time_emb)\n",
    "\n",
    "        # Final output\n",
    "        h = self.final_norm(h)\n",
    "        h = F.silu(h)\n",
    "        h = self.final_conv(h)\n",
    "\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f75a7e",
   "metadata": {},
   "source": [
    "## Solution 6: Training Step with MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee03aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_0, scheduler, device):\n",
    "    \"\"\"\n",
    "    Single training step with MSE loss.\n",
    "\n",
    "    Core of diffusion model training:\n",
    "    - Sample random timesteps\n",
    "    - Apply forward diffusion to create noisy images\n",
    "    - Train model to predict the noise\n",
    "    - Use MSE loss (not adversarial)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    x_0 = x_0.to(device)\n",
    "    batch_size = x_0.shape[0]\n",
    "\n",
    "    # Sample random timesteps (0 to num_timesteps-1)\n",
    "    timesteps = torch.randint(0, scheduler.num_timesteps, (batch_size,), device=device)\n",
    "\n",
    "    # Sample random noise\n",
    "    noise = torch.randn_like(x_0)\n",
    "\n",
    "    # Apply forward diffusion\n",
    "    x_t, _ = add_noise(x_0, timesteps, scheduler, noise)\n",
    "\n",
    "    # Predict noise with model\n",
    "    predicted_noise = model(x_t, timesteps)\n",
    "\n",
    "    # Compute MSE loss (main advantage over cGAN!)\n",
    "    loss = F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be80fb3",
   "metadata": {},
   "source": [
    "## Solution 7: Training Loop Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"\\nDataset loaded: {len(train_dataset)} images\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f0be7",
   "metadata": {},
   "source": [
    "## Solution 8: Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04508684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and scheduler\n",
    "model = SimpleUNet(image_channels=1, base_channels=64, time_embedding_dim=128)\n",
    "model = model.to(device)\n",
    "\n",
    "scheduler = NoiseScheduler(num_timesteps=1000, beta_start=0.0001, beta_end=0.02)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "print(\"\\nModel created:\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"\\nTraining for 10 epochs...\\n\")\n",
    "\n",
    "# Training loop (shortened for demonstration)\n",
    "num_epochs = 10\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        loss = train_step(model, optimizer, images, scheduler, device)\n",
    "        epoch_loss += loss\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ceac7d",
   "metadata": {},
   "source": [
    "## Visualize Training Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1749804",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Diffusion Model Training Loss\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nLoss Summary:\")\n",
    "print(f\"  Initial: {losses[0]:.4f}\")\n",
    "print(f\"  Final: {losses[-1]:.4f}\")\n",
    "print(f\"  Improvement: {(losses[0] - losses[-1]) / losses[0] * 100:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
