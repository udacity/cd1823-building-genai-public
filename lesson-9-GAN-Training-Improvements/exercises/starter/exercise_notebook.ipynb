{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55af826c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaecbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all required libraries\n",
    "# You'll need: os, sys, torch, matplotlib.pyplot, numpy, torchvision\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# from improved_gan_training import (\n",
    "#     BaselineGAN,\n",
    "#     LabelSmoothingGAN,\n",
    "#     FeatureMatchingGAN,\n",
    "#     ComparisonTrainer,\n",
    "# )\n",
    "\n",
    "# from models.basic_gan import create_generator, create_discriminator\n",
    "print(\" All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74946d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers \n",
    "def plot_loss_comparison(results):\n",
    "    \"\"\"Plot loss curves for all three GAN variants.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    colors = {\n",
    "        \"Baseline\": \"navy\",\n",
    "        \"Label Smoothing\": \"orange\",\n",
    "        \"Feature Matching\": \"green\",\n",
    "    }\n",
    "\n",
    "    # Plot discriminator losses\n",
    "    ax = axes[0]\n",
    "    for variant_name, losses in results.items():\n",
    "        d_losses = losses[\"d_losses\"]\n",
    "        ax.plot(\n",
    "            d_losses,\n",
    "            label=variant_name,\n",
    "            color=colors.get(variant_name, \"blue\"),\n",
    "            alpha=0.8,\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "    ax.axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "    ax.set_xlabel(\"Training Step\", fontsize=11)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=11)\n",
    "    ax.set_title(\"Discriminator Loss Comparison\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    # Plot generator losses\n",
    "    ax = axes[1]\n",
    "    for variant_name, losses in results.items():\n",
    "        g_losses = losses[\"g_losses\"]\n",
    "        ax.plot(\n",
    "            g_losses,\n",
    "            label=variant_name,\n",
    "            color=colors.get(variant_name, \"blue\"),\n",
    "            alpha=0.8,\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "    ax.set_xlabel(\"Training Step\", fontsize=11)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=11)\n",
    "    ax.set_title(\"Generator Loss Comparison\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_stability_metrics(metrics):\n",
    "    \"\"\"Create 2x2 comparison visualization of training stability metrics.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    variants = list(metrics.keys())\n",
    "    x_pos = np.arange(len(variants))\n",
    "    width = 0.6\n",
    "    colors_list = [\"navy\", \"orange\", \"green\"]\n",
    "\n",
    "    # Subplot 1: Average D Loss\n",
    "    ax = axes[0, 0]\n",
    "    d_losses = [metrics[v][\"avg_d_loss\"] for v in variants]\n",
    "    bars = ax.bar(x_pos, d_losses, width, color=colors_list[: len(variants)], alpha=0.8)\n",
    "    ax.axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "    ax.set_ylabel(\"Loss\", fontsize=11)\n",
    "    ax.set_title(\"Average D Loss (Last 100 Batches)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    # Subplot 2: D Loss Stability (Std Dev)\n",
    "    ax = axes[0, 1]\n",
    "    std_d_loss = [metrics[v][\"std_d_loss\"] for v in variants]\n",
    "    bars = ax.bar(\n",
    "        x_pos, std_d_loss, width, color=colors_list[: len(variants)], alpha=0.8\n",
    "    )\n",
    "    ax.set_ylabel(\"Std Dev\", fontsize=11)\n",
    "    ax.set_title(\"D Loss Stability (Lower = Better)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # Subplot 3: Average G Loss\n",
    "    ax = axes[1, 0]\n",
    "    g_losses = [metrics[v][\"avg_g_loss\"] for v in variants]\n",
    "    bars = ax.bar(x_pos, g_losses, width, color=colors_list[: len(variants)], alpha=0.8)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=11)\n",
    "    ax.set_title(\"Average G Loss (Last 100 Batches)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # Subplot 4: D Loss Oscillation\n",
    "    ax = axes[1, 1]\n",
    "    d_osc = [metrics[v][\"d_oscillation\"] for v in variants]\n",
    "    bars = ax.bar(x_pos, d_osc, width, color=colors_list[: len(variants)], alpha=0.8)\n",
    "    ax.set_ylabel(\"Oscillation\", fontsize=11)\n",
    "    ax.set_title(\n",
    "        \"D Loss Oscillation (Lower = Smoother)\", fontsize=11, fontweight=\"bold\"\n",
    "    )\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\" Visualization helpers loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f475f8",
   "metadata": {},
   "source": [
    "## Part 1: Setup Device and Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up device\n",
    "# Check for MPS (Apple GPU), CUDA (NVIDIA GPU), or CPU\n",
    "# Set random seed to 42\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# elif torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d739537",
   "metadata": {},
   "source": [
    "## Part 2: Load Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create transforms for Fashion MNIST\n",
    "# Transforms needed:\n",
    "# 1. ToTensor() - convert images to tensors\n",
    "# 2. Normalize((0.5,), (0.5,)) - normalize to [-1, 1] range\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     # TODO: Add transforms here\n",
    "# ])\n",
    "\n",
    "# print(\"Loading Fashion MNIST dataset...\")\n",
    "\n",
    "# TODO: Load FashionMNIST dataset\n",
    "# Parameters:\n",
    "# - root='./data'\n",
    "# - train=True (use training set)\n",
    "# - download=True (download if not present)\n",
    "# - transform=transform\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(...)\n",
    "\n",
    "# TODO: Create DataLoader\n",
    "batch_size = 64\n",
    "# train_loader = DataLoader(...)\n",
    "\n",
    "# print(f\" Dataset loaded\")\n",
    "# print(f\"  Total images: {len(train_dataset)}\")\n",
    "# print(f\"  Batch size: {batch_size}\")\n",
    "# print(f\"  Batches per epoch: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eed538",
   "metadata": {},
   "source": [
    "## Part 3: Create Comparison Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe10af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize ComparisonTrainer\n",
    "# This will handle training all three variants\n",
    "\n",
    "# trainer = ComparisonTrainer(device=device)\n",
    "# print(\"Comparison trainer initialized\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a8d8657",
   "metadata": {},
   "source": [
    "## Part 4: Train All Variants\n",
    "\n",
    " **WARNING**: This will take 15-20 minutes. Training three models × 50 epochs each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bea67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call train_all_variants()\n",
    "# This trains three GAN models: Baseline, Label Smoothing, Feature Matching\n",
    "# Each trained for 50 epochs\n",
    "#\n",
    "# Parameters:\n",
    "# - generator_class=create_generator\n",
    "# - discriminator_class=create_discriminator\n",
    "# - train_loader=train_loader\n",
    "# - num_epochs=50\n",
    "# - lr=0.0002\n",
    "# - beta1=0.5\n",
    "\n",
    "# print(\"Training three GAN variants...\")\n",
    "# print(\"(This will take ~15-20 minutes)\\n\")\n",
    "\n",
    "# results = trainer.train_all_variants(\n",
    "#     generator_class=create_generator,\n",
    "#     discriminator_class=create_discriminator,\n",
    "#     train_loader=train_loader,\n",
    "#     num_epochs=50,\n",
    "#     lr=0.0002,\n",
    "#     beta1=0.5,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c4b78",
   "metadata": {},
   "source": [
    "## Part 5: Visualize Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot loss curves for all three variants using helper\n",
    "plot_loss_comparison(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a677abe1",
   "metadata": {},
   "source": [
    "## Part 6: Compute Stability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get stability metrics\n",
    "# Call trainer.get_stability_metrics()\n",
    "# This computes for each variant (last 100 batches):\n",
    "#   - avg_d_loss: Average discriminator loss\n",
    "#   - std_d_loss: Standard deviation (stability)\n",
    "#   - avg_g_loss: Average generator loss\n",
    "#   - std_g_loss: Generator stability\n",
    "#   - d_oscillation: How much D loss bounces around\n",
    "#   - g_oscillation: How much G loss bounces around\n",
    "\n",
    "# metrics = trainer.get_stability_metrics()\n",
    "\n",
    "# TODO: Print metrics for each variant\n",
    "# for variant_name, metric_dict in metrics.items():\n",
    "#     print(f\"{variant_name}:\")\n",
    "#     print(f\"  Discriminator Loss:\")\n",
    "#     print(f\"    Average: {metric_dict['avg_d_loss']:.4f}\")\n",
    "#     print(f\"    Std Dev: {metric_dict['std_d_loss']:.4f}\")\n",
    "#     print(f\"    Oscillation: {metric_dict['d_oscillation']:.6f}\")\n",
    "#     print(f\"  Generator Loss:\")\n",
    "#     print(f\"    Average: {metric_dict['avg_g_loss']:.4f}\")\n",
    "#     print(f\"    Std Dev: {metric_dict['std_g_loss']:.4f}\")\n",
    "#     print(f\"    Oscillation: {metric_dict['g_oscillation']:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ec338",
   "metadata": {},
   "source": [
    "## Part 7: Create Comparison Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create 2×2 comparison visualization using helper\n",
    "plot_stability_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f40ae5",
   "metadata": {},
   "source": [
    "## Part 8: Print Detailed Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call trainer.print_comparison_report()\n",
    "# This will print:\n",
    "# - Detailed metrics for each variant\n",
    "# - Best variant for each metric\n",
    "# - Analysis of training stability\n",
    "\n",
    "# trainer.print_comparison_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437eb53d",
   "metadata": {},
   "source": [
    "## Part 9: Analysis Questions\n",
    "\n",
    "Answer these based on your experimental results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nANALYSIS QUESTIONS - Answer based on your results:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. Which technique produced the most stable training?\")\n",
    "print(\"   (Look for lowest std_d_loss across all batches)\")\n",
    "print(\"   Answer: \")\n",
    "# TODO: Your answer here\n",
    "\n",
    "print(\"\\n2. Which technique kept D loss closest to the ideal 0.5?\")\n",
    "print(\"   (Ideal: discriminator confused but not useless)\")\n",
    "print(\"   Answer: \")\n",
    "# TODO: Your answer here\n",
    "\n",
    "print(\"\\n3. Which technique showed the least oscillation?\")\n",
    "print(\"   (Smoother curves = better gradient flow)\")\n",
    "print(\"   Answer: \")\n",
    "# TODO: Your answer here\n",
    "\n",
    "print(\"\\n4. Did any variant show signs of mode collapse?\")\n",
    "print(\"   (Signs: D loss → 0, G loss → ∞, visual artifacts in samples)\")\n",
    "print(\"   Answer: \")\n",
    "# TODO: Your answer here\n",
    "\n",
    "print(\"\\n5. Rank the techniques 1-3 by overall performance:\")\n",
    "print(\"   (Consider stability, D loss balance, and practical usefulness)\")\n",
    "print(\"   Answer: \")\n",
    "# TODO: Your answer here\n",
    "\n",
    "print(\"\\n6. Would you combine techniques or use one alone?\")\n",
    "print(\"   (Why or why not?)\")\n",
    "print(\"   Answer: \")\n",
    "# TODO: Your answer here\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c5e6bff",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Did:**\n",
    "1. Trained three GAN variants with different stabilization techniques\n",
    "2. Measured training stability using multiple metrics\n",
    "3. Compared loss curves and identified differences\n",
    "4. Analyzed which technique worked best\n",
    "5. Made data-driven recommendations\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Label Smoothing: Simple, quick win for stability\n",
    "- Feature Matching: More complex, but better for sample quality\n",
    "- Combining both: Often best, but requires more tuning\n",
    "- Empirical testing: Always measure rather than guess!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce6ebf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
