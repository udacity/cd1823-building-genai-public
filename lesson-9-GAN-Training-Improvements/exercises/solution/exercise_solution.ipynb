{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766551ae",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6597c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import improved training module\n",
    "from improved_gan_training import (\n",
    "    BaselineGAN,\n",
    "    ComparisonTrainer,\n",
    "    FeatureMatchingGAN,\n",
    "    LabelSmoothingGAN,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models.basic_gan import create_generator, create_discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b06a6",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up environment...\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0935136",
   "metadata": {},
   "source": [
    "## Load Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b46e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard transforms: convert to tensor and normalize to [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # mean=0.5, std=0.5 → range [-1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Loading Fashion MNIST dataset...\")\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset loaded\")\n",
    "print(f\"  Total images: {len(train_dataset)}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Batches per epoch: {len(train_loader)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8f272",
   "metadata": {},
   "source": [
    "## Create Comparison Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e316e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing comparison trainer...\\n\")\n",
    "trainer = ComparisonTrainer(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c8b8d",
   "metadata": {},
   "source": [
    "## Train All Variants\n",
    "\n",
    "This will train three GAN variants for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e28a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TRAINING THREE GAN VARIANTS\")\n",
    "print(\"(This will take ~15-20 minutes depending on your device)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "results = trainer.train_all_variants(\n",
    "    generator_class=create_generator,\n",
    "    discriminator_class=create_discriminator,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=50,\n",
    "    lr=0.0002,\n",
    "    beta1=0.5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d321c",
   "metadata": {},
   "source": [
    "## Visualize Loss Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b584db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VISUALIZING RESULTS\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "colors = {\n",
    "    \"Baseline\": \"navy\",\n",
    "    \"Label Smoothing\": \"orange\",\n",
    "    \"Feature Matching\": \"green\",\n",
    "}\n",
    "alphas = {\"Baseline\": 0.8, \"Label Smoothing\": 0.8, \"Feature Matching\": 0.8}\n",
    "\n",
    "# Discriminator losses\n",
    "ax = axes[0]\n",
    "for variant_name, losses in results.items():\n",
    "    d_losses = losses[\"d_losses\"]\n",
    "    ax.plot(\n",
    "        d_losses,\n",
    "        label=variant_name,\n",
    "        color=colors.get(variant_name, \"blue\"),\n",
    "        alpha=alphas.get(variant_name, 0.7),\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "ax.axhline(y=0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "ax.set_xlabel(\"Training Step\", fontsize=11)\n",
    "ax.set_ylabel(\"Discriminator Loss\", fontsize=11)\n",
    "ax.set_title(\"Discriminator Loss Comparison\", fontsize=12, fontweight=\"bold\")\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Generator losses\n",
    "ax = axes[1]\n",
    "for variant_name, losses in results.items():\n",
    "    g_losses = losses[\"g_losses\"]\n",
    "    ax.plot(\n",
    "        g_losses,\n",
    "        label=variant_name,\n",
    "        color=colors.get(variant_name, \"blue\"),\n",
    "        alpha=alphas.get(variant_name, 0.7),\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Training Step\", fontsize=11)\n",
    "ax.set_ylabel(\"Generator Loss\", fontsize=11)\n",
    "ax.set_title(\"Generator Loss Comparison\", fontsize=12, fontweight=\"bold\")\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382ae4d",
   "metadata": {},
   "source": [
    "## Compute Stability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nComputing stability metrics...\\n\")\n",
    "metrics = trainer.get_stability_metrics()\n",
    "\n",
    "print(\"Stability Metrics (Last 100 Batches):\")\n",
    "print(\"=\" * 80)\n",
    "for variant_name, metric_dict in metrics.items():\n",
    "    print(f\"\\n{variant_name}:\")\n",
    "    print(f\"  Discriminator Loss:\")\n",
    "    print(f\"    Average: {metric_dict['avg_d_loss']:.4f}\")\n",
    "    print(f\"    Std Dev: {metric_dict['std_d_loss']:.4f}\")\n",
    "    print(f\"    Oscillation: {metric_dict['d_oscillation']:.6f}\")\n",
    "    print(f\"  Generator Loss:\")\n",
    "    print(f\"    Average: {metric_dict['avg_g_loss']:.4f}\")\n",
    "    print(f\"    Std Dev: {metric_dict['std_g_loss']:.4f}\")\n",
    "    print(f\"    Oscillation: {metric_dict['g_oscillation']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f10e8",
   "metadata": {},
   "source": [
    "## Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "variants = list(metrics.keys())\n",
    "x_pos = np.arange(len(variants))\n",
    "width = 0.35\n",
    "\n",
    "# Average D Loss\n",
    "ax = axes[0, 0]\n",
    "d_losses = [metrics[v][\"avg_d_loss\"] for v in variants]\n",
    "bars = ax.bar(\n",
    "    x_pos,\n",
    "    d_losses,\n",
    "    color=[colors.get(v, \"blue\") for v in variants],\n",
    "    alpha=0.7,\n",
    "    width=width,\n",
    ")\n",
    "ax.axhline(y=0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "ax.set_ylabel(\"Average D Loss\", fontsize=10)\n",
    "ax.set_title(\n",
    "    \"Average Discriminator Loss (Last 100 Batches)\", fontsize=11, fontweight=\"bold\"\n",
    ")\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "# D Loss Stability (Std Dev)\n",
    "ax = axes[0, 1]\n",
    "d_stds = [metrics[v][\"std_d_loss\"] for v in variants]\n",
    "bars = ax.bar(\n",
    "    x_pos,\n",
    "    d_stds,\n",
    "    color=[colors.get(v, \"blue\") for v in variants],\n",
    "    alpha=0.7,\n",
    "    width=width,\n",
    ")\n",
    "ax.set_ylabel(\"Std Dev of D Loss\", fontsize=10)\n",
    "ax.set_title(\"D Loss Stability (Lower is Better)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "ax.grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Average G Loss\n",
    "ax = axes[1, 0]\n",
    "g_losses = [metrics[v][\"avg_g_loss\"] for v in variants]\n",
    "bars = ax.bar(\n",
    "    x_pos,\n",
    "    g_losses,\n",
    "    color=[colors.get(v, \"blue\") for v in variants],\n",
    "    alpha=0.7,\n",
    "    width=width,\n",
    ")\n",
    "ax.set_ylabel(\"Average G Loss\", fontsize=10)\n",
    "ax.set_title(\n",
    "    \"Average Generator Loss (Last 100 Batches)\", fontsize=11, fontweight=\"bold\"\n",
    ")\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "ax.grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Loss Oscillation\n",
    "ax = axes[1, 1]\n",
    "d_osc = [metrics[v][\"d_oscillation\"] for v in variants]\n",
    "bars = ax.bar(\n",
    "    x_pos,\n",
    "    d_osc,\n",
    "    color=[colors.get(v, \"blue\") for v in variants],\n",
    "    alpha=0.7,\n",
    "    width=width,\n",
    ")\n",
    "ax.set_ylabel(\"D Loss Oscillation\", fontsize=10)\n",
    "ax.set_title(\n",
    "    \"Loss Oscillation (Lower = Smoother Training)\", fontsize=11, fontweight=\"bold\"\n",
    ")\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(variants, rotation=15, ha=\"right\")\n",
    "ax.grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf49fe",
   "metadata": {},
   "source": [
    "## Detailed Comparison Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d534b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.print_comparison_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff2fa2",
   "metadata": {},
   "source": [
    "## Analysis and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44587f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nANSWERS TO KEY QUESTIONS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n1. Which technique produced the most stable training?\")\n",
    "print(\"   Looking at Std Dev of D Loss (lowest is best)...\")\n",
    "best_stability = min(metrics.items(), key=lambda x: x[1][\"std_d_loss\"])\n",
    "print(f\"   WINNER: {best_stability[0]}\")\n",
    "print(f\"     Std Dev: {best_stability[1]['std_d_loss']:.6f}\")\n",
    "print(\"   Why: Lower variance means more consistent loss curve → better learning\")\n",
    "\n",
    "print(\"\\n2. Which technique kept D loss closest to the ideal 0.5?\")\n",
    "print(\"   Looking for balance (not too good, not too bad)...\")\n",
    "best_balance = min(metrics.items(), key=lambda x: abs(x[1][\"avg_d_loss\"] - 0.5))\n",
    "print(f\"    WINNER: {best_balance[0]}\")\n",
    "print(f\"     Average D Loss: {best_balance[1]['avg_d_loss']:.4f}\")\n",
    "print(\"   Why: Balanced loss indicates good G-D competition\")\n",
    "\n",
    "print(\"\\n3. Which technique showed the smoothest training (least oscillation)?\")\n",
    "print(\"   Looking at D Loss Oscillation (lowest is best)...\")\n",
    "best_smooth = min(metrics.items(), key=lambda x: x[1][\"d_oscillation\"])\n",
    "print(f\"    WINNER: {best_smooth[0]}\")\n",
    "print(f\"     Oscillation: {best_smooth[1]['d_oscillation']:.6f}\")\n",
    "print(\"   Why: Smooth training helps avoid mode collapse and instability\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
