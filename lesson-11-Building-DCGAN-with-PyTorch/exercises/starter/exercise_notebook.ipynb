{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6333c637",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c73c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "\n",
    "# Set up device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\" Setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e420d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers (provided - focus on the model!)\n",
    "def plot_loss_curves(d_losses, g_losses):\n",
    "    \"\"\"Plot discriminator and generator losses.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    axes[0].plot(d_losses, linewidth=2, color=\"navy\", label=\"D Loss\")\n",
    "    axes[0].axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Discriminator Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    axes[1].plot(g_losses, linewidth=2, color=\"darkgreen\", label=\"G Loss\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[1].set_title(\"Generator Loss\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_generated_images(generator, num_samples=16, device=\"cpu\"):\n",
    "    \"\"\"Generate and display images.\"\"\"\n",
    "    generator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, 100, device=device)\n",
    "        images = generator(z)\n",
    "\n",
    "    # Denormalize\n",
    "    images = (images + 1) / 2\n",
    "    images = torch.clamp(images, 0, 1)\n",
    "\n",
    "    # Display\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Generated Images\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Visualization helpers loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d242b1",
   "metadata": {},
   "source": [
    "## TODO 1: Load CIFAR-10 Dataset\n",
    "\n",
    "**What to do:**\n",
    "- Define transforms: ToTensor() and Normalize to [-1, 1]\n",
    "- Load CIFAR-10 training dataset\n",
    "- Create DataLoader with batch_size=64 and shuffle=True\n",
    "\n",
    "**Hints:**\n",
    "- Use `transforms.Compose()` to chain operations\n",
    "- Use `transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))` for [-1, 1] normalization\n",
    "- Use `datasets.CIFAR10()` with `download=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Load CIFAR-10 Dataset\n",
    "# TODO: Define transforms\n",
    "transform = None  # Replace with your implementation\n",
    "\n",
    "# TODO: Load dataset\n",
    "train_dataset = None  # Replace with your implementation\n",
    "\n",
    "# TODO: Create DataLoader\n",
    "batch_size = 64\n",
    "train_loader = None  # Replace with your implementation\n",
    "\n",
    "# Verify\n",
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Image shape: {train_dataset[0][0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7272b",
   "metadata": {},
   "source": [
    "## TODO 2: Build Generator Network\n",
    "\n",
    "**Architecture:**\n",
    "- Input: Noise vector (batch, 100)\n",
    "- FC layer: 100 → 256 * 8 * 8 = 16,384\n",
    "- Reshape to (256, 8, 8)\n",
    "- ConvTranspose block 1: 8×8 → 16×16 (256 → 128 channels)\n",
    "- ConvTranspose block 2: 16×16 → 32×32 (128 → 64 channels)\n",
    "- Output layer: 64 → 3 channels with **Tanh** activation\n",
    "\n",
    "**Use:** `nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Implement Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, num_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: FC layer from latent_dim to 256*8*8\n",
    "        self.fc = None\n",
    "\n",
    "        # TODO: ConvTranspose blocks\n",
    "        # - 256x8x8 -> 128x16x16 (with BatchNorm + ReLU)\n",
    "        # - 128x16x16 -> 64x32x32 (with BatchNorm + ReLU)\n",
    "        # - 64x32x32 -> 3x32x32 (with Tanh, no BatchNorm)\n",
    "        self.main = None\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z: (batch, latent_dim)\n",
    "        # TODO: FC -> reshape to (batch, 256, 8, 8) -> main -> output\n",
    "        pass\n",
    "\n",
    "\n",
    "generator = Generator(latent_dim=100, num_channels=3).to(device)\n",
    "print(\n",
    "    f\"Generator created. Parameters: {sum(p.numel() for p in generator.parameters()):,}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad241d",
   "metadata": {},
   "source": [
    "## TODO 3: Build Discriminator Network\n",
    "\n",
    "**Architecture:**\n",
    "- Input: Image (batch, 3, 32, 32)\n",
    "- Conv block 1: 32×32 → 16×16 (3 → 64 channels)\n",
    "- Conv block 2: 16×16 → 8×8 (64 → 128 channels)\n",
    "- Conv block 3: 8×8 → 4×4 (128 → 256 channels)\n",
    "- Flatten to (256 * 4 * 4) = 4,096 features\n",
    "- FC: 4096 → 1024 → 1 with Sigmoid output\n",
    "\n",
    "**Use:** `nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bc6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: Implement Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Conv blocks (no BatchNorm on first, then BatchNorm + LeakyReLU)\n",
    "        # - 3x32x32 -> 64x16x16 (LeakyReLU only)\n",
    "        # - 64x16x16 -> 128x8x8 (BatchNorm + LeakyReLU)\n",
    "        # - 128x8x8 -> 256x4x4 (BatchNorm + LeakyReLU)\n",
    "        self.main = None\n",
    "\n",
    "        # TODO: FC layers to output\n",
    "        # - Flatten -> 4096 -> 1024 -> 1 (with Sigmoid)\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, 3, 32, 32)\n",
    "        # TODO: Conv blocks -> flatten -> fc -> output\n",
    "        pass\n",
    "\n",
    "\n",
    "discriminator = Discriminator(num_channels=3).to(device)\n",
    "print(\n",
    "    f\"Discriminator created. Parameters: {sum(p.numel() for p in discriminator.parameters()):,}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfbf9c",
   "metadata": {},
   "source": [
    "## TODO 4: Weight Initialization\n",
    "\n",
    "**DCGAN standard:**\n",
    "- Conv/ConvTranspose: `Normal(mean=0, std=0.02)`\n",
    "- BatchNorm: `Normal(mean=1, std=0.02)` weight, bias=0\n",
    "\n",
    "**Use:**\n",
    "- `nn.init.normal_(m.weight, 0.0, 0.02)`\n",
    "- `nn.init.normal_(m.weight, 1.0, 0.02)` for BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abca72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Implement weight initialization\n",
    "def initialize_weights(model):\n",
    "    # TODO: Iterate through model.modules()\n",
    "    # - For Conv2d/ConvTranspose2d: nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    # - For BatchNorm2d: nn.init.normal_(m.weight, 1.0, 0.02), nn.init.constant_(m.bias, 0.0)\n",
    "    pass\n",
    "\n",
    "\n",
    "initialize_weights(generator)\n",
    "initialize_weights(discriminator)\n",
    "print(\"✓ Weights initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c384ea",
   "metadata": {},
   "source": [
    "## TODO 5: Set Up Optimizers and Loss\n",
    "\n",
    "**Configuration:**\n",
    "- Adam optimizer with lr=0.0002, beta1=0.5, beta2=0.999\n",
    "- BCELoss for real/fake classification\n",
    "\n",
    "**Note:** beta1=0.5 is unusual but empirically works better for GANs than default 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Set up optimizers and loss\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# TODO: Create Adam optimizers for G and D\n",
    "optimizer_g = None  # Replace with your implementation\n",
    "optimizer_d = None  # Replace with your implementation\n",
    "\n",
    "# TODO: Create BCELoss criterion\n",
    "criterion = None  # Replace with your implementation\n",
    "\n",
    "print(\"✓ Optimizers and loss initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c126f5",
   "metadata": {},
   "source": [
    "## TODO 6: Implement Training Loop\n",
    "\n",
    "**Discriminator step:**\n",
    "1. Forward real images → target=1\n",
    "2. Generate fake images (detached)\n",
    "3. Forward fake images → target=0\n",
    "4. Sum losses and backprop\n",
    "\n",
    "**Generator step:**\n",
    "1. Generate fake images (NOT detached)\n",
    "2. Forward through discriminator\n",
    "3. Try to fool D → target=1\n",
    "4. Backprop generator only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6: Training loop\n",
    "num_epochs = 20\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "\n",
    "    for batch_idx, (real_images, _) in enumerate(train_loader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # TODO: Discriminator step\n",
    "        # 1. optimizer_d.zero_grad()\n",
    "        # 2. Forward real images, compute loss with target=1\n",
    "        # 3. Generate fake images with torch.randn(batch_size, 100, device=device)\n",
    "        # 4. Forward fake images (detached!), compute loss with target=0\n",
    "        # 5. d_loss = real_loss + fake_loss\n",
    "        # 6. d_loss.backward() and optimizer_d.step()\n",
    "        pass\n",
    "\n",
    "        # TODO: Generator step\n",
    "        # 1. optimizer_g.zero_grad()\n",
    "        # 2. Generate new fake images (no detach)\n",
    "        # 3. Forward through discriminator\n",
    "        # 4. Compute loss with target=1 (fool D)\n",
    "        # 5. g_loss.backward() and optimizer_g.step()\n",
    "        pass\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}\"\n",
    "            )\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} complete\")\n",
    "\n",
    "print(\"✓ Training complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f52676",
   "metadata": {},
   "source": [
    "## TODO 7: Plot Loss Curves\n",
    "\n",
    "**What to look for:**\n",
    "- D loss stabilizes around 0.5\n",
    "- G loss generally decreases\n",
    "- No divergence or wild oscillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa940321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 7: Plot loss curves\n",
    "plot_loss_curves(d_losses, g_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd64c9b",
   "metadata": {},
   "source": [
    "## TODO 8: Generate and Visualize Images\n",
    "\n",
    "**Steps:**\n",
    "1. Set generator to eval mode\n",
    "2. Generate 16 samples with `torch.no_grad()`\n",
    "3. Denormalize: `(generated + 1) / 2` and clamp to [0, 1]\n",
    "4. Display as 4×4 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 8: Generate and visualize images\n",
    "visualize_generated_images(generator, num_samples=16, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0695bc",
   "metadata": {},
   "source": [
    "## TODO 9: Analysis\n",
    "\n",
    "Write your observations about:\n",
    "1. Image quality and realism\n",
    "2. Patterns and diversity\n",
    "3. Loss curve behavior\n",
    "4. Potential improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce82a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9: Write your analysis\n",
    "# TODO: Replace with your observations\n",
    "\n",
    "analysis = \"\"\"\n",
    "ANALYSIS:\n",
    "\n",
    "[Your analysis here]\n",
    "\"\"\"\n",
    "\n",
    "print(analysis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
