{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06c526eb",
   "metadata": {},
   "source": [
    "# Exercise: Comparing Sampling Schedules\n",
    "\n",
    "\n",
    "In this notebook, you'll implement and compare two different sampling schedules for reverse diffusion:\n",
    "- **Linear Schedule**: Uniform timestep spacing\n",
    "- **Cosine Schedule**: Non-linear spacing focusing on high-noise steps\n",
    "\n",
    "By the end, you'll understand how scheduling affects generation quality without changing computational cost.\n",
    "\n",
    "**Learning Objectives:**\n",
    "+ Implement timestep scheduling strategies\n",
    "+ Understand reverse diffusion step-by-step  \n",
    "+ Compare quality-speed tradeoffs\n",
    "+ Analyze sampling schedule impact\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e3dd2",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d162e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load Fashion MNIST\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "fashion_mnist = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Fashion MNIST loaded: {len(fashion_mnist)} images\")\n",
    "print(f\"Image shape: {fashion_mnist[0][0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904dd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers \n",
    "def plot_sample_comparison(linear_samples, cosine_samples, num_cols=4):\n",
    "    \"\"\"Display side-by-side comparison of linear vs cosine sampled images.\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_cols, figsize=(16, 8))\n",
    "\n",
    "    for i in range(num_cols):\n",
    "        # Linear samples (top row)\n",
    "        img_linear = (linear_samples[i] + 1) / 2  # Denormalize\n",
    "        img_linear = torch.clamp(img_linear, 0, 1)\n",
    "        axes[0, i].imshow(img_linear.cpu().squeeze(), cmap=\"gray\")\n",
    "        axes[0, i].set_title(f\"Linear #{i+1}\", fontsize=11, fontweight=\"bold\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        # Cosine samples (bottom row)\n",
    "        img_cosine = (cosine_samples[i] + 1) / 2  # Denormalize\n",
    "        img_cosine = torch.clamp(img_cosine, 0, 1)\n",
    "        axes[1, i].imshow(img_cosine.cpu().squeeze(), cmap=\"gray\")\n",
    "        axes[1, i].set_title(f\"Cosine #{i+1}\", fontsize=11, fontweight=\"bold\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Sampling Schedule Comparison\\nTop: Linear Schedule | Bottom: Cosine Schedule\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        y=0.98,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_denoising_trajectory(trajectory, schedule_name=\"Schedule\", num_steps=8):\n",
    "    \"\"\"Plot denoising trajectory showing progression from noise to image.\"\"\"\n",
    "    # Select evenly spaced steps from trajectory\n",
    "    indices = np.linspace(0, len(trajectory) - 1, num_steps, dtype=int)\n",
    "    selected_steps = [trajectory[i] for i in indices]\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_steps, figsize=(16, 3))\n",
    "\n",
    "    for idx, (step_idx, img) in enumerate(selected_steps):\n",
    "        img_display = (img + 1) / 2  # Denormalize\n",
    "        img_display = torch.clamp(img_display, 0, 1)\n",
    "        axes[idx].imshow(img_display.cpu().squeeze(), cmap=\"gray\")\n",
    "        axes[idx].set_title(f\"Step {step_idx}\", fontsize=10, fontweight=\"bold\")\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Denoising Trajectory: {schedule_name}\\nProgression from noise to sample\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_schedule_metrics(linear_metrics, cosine_metrics):\n",
    "    \"\"\"Plot quality metrics comparison between schedules.\"\"\"\n",
    "    metrics = [\"Variance\", \"Sharpness\", \"Mean\"]\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    linear_vals = [linear_metrics.get(m, 0) for m in metrics]\n",
    "    cosine_vals = [cosine_metrics.get(m, 0) for m in metrics]\n",
    "\n",
    "    ax.bar(x - width / 2, linear_vals, width, label=\"Linear Schedule\", alpha=0.8)\n",
    "    ax.bar(x + width / 2, cosine_vals, width, label=\"Cosine Schedule\", alpha=0.8)\n",
    "\n",
    "    ax.set_ylabel(\"Metric Value\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        \"Sampling Schedule Comparison: Quality Metrics\", fontsize=13, fontweight=\"bold\"\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\" Visualization helpers loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e2817e",
   "metadata": {},
   "source": [
    "## Section 2: Load Pre-trained U-Net Model\n",
    "\n",
    "Import the model and load checkpoint from Module 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Load pre-trained model\n",
    "# For now, we'll create a simple placeholder model structure\n",
    "# Replace with actual checkpoint loading from Module 16\n",
    "\n",
    "\n",
    "# Define a simple UNet for demonstration\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.enc2 = nn.Conv2d(64, 128, 3, padding=1, stride=2)\n",
    "        self.enc3 = nn.Conv2d(128, 256, 3, padding=1, stride=2)\n",
    "\n",
    "        # Middle\n",
    "        self.mid = nn.Conv2d(256, 256, 3, padding=1)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec3 = nn.ConvTranspose2d(256, 128, 4, padding=1, stride=2)\n",
    "        self.dec2 = nn.ConvTranspose2d(128, 64, 4, padding=1, stride=2)\n",
    "        self.dec1 = nn.Conv2d(64, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Simple UNet (in practice, t would be embedded and added at each layer)\n",
    "        x1 = F.relu(self.enc1(x))\n",
    "        x2 = F.relu(self.enc2(x1))\n",
    "        x3 = F.relu(self.enc3(x2))\n",
    "\n",
    "        x = F.relu(self.mid(x3))\n",
    "\n",
    "        x = F.relu(self.dec3(x + x3))\n",
    "        x = F.relu(self.dec2(x + x2))\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Load or create model\n",
    "model = SimpleUNet().to(device)\n",
    "model.eval()\n",
    "\n",
    "# Try to load checkpoint if it exists\n",
    "checkpoint_path = \"../../lesson-16-Implementing-Simple-Diffusion-Model/checkpoint.pt\"\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\" Loaded checkpoint from {checkpoint_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Could not find checkpoint at {checkpoint_path}\")\n",
    "    print(\"  Using untrained model (for demonstration only)\")\n",
    "\n",
    "print(f\"Model loaded: {type(model).__name__}\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2fd3b",
   "metadata": {},
   "source": [
    "## Section 3: Implement DDPM Reverse Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecff756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noise schedule (pre-computed)\n",
    "num_timesteps = 1000\n",
    "betas = torch.linspace(0.0001, 0.02, num_timesteps, device=device)\n",
    "alphas = 1 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alphas_cumprod_prev = torch.cat([torch.ones(1, device=device), alphas_cumprod[:-1]])\n",
    "\n",
    "print(f\"Noise schedule configured:\")\n",
    "print(f\"  Total timesteps: {num_timesteps}\")\n",
    "print(f\"  Alpha cumprod shape: {alphas_cumprod.shape}\")\n",
    "print(f\"  Alphas cumprod range: [{alphas_cumprod[-1]:.6f}, {alphas_cumprod[0]:.6f}]\")\n",
    "\n",
    "\n",
    "# TODO 2: Implement reverse_diffusion_step\n",
    "def reverse_diffusion_step(\n",
    "    x_t, t, predicted_noise, alphas_cumprod, alphas_cumprod_prev, betas, device\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform one reverse diffusion step: x_t → x_{t-1}\n",
    "\n",
    "    Args:\n",
    "        x_t: Current noisy image (batch, 1, 28, 28)\n",
    "        t: Current timestep index (int)\n",
    "        predicted_noise: U-Net prediction (batch, 1, 28, 28)\n",
    "        alphas_cumprod: Pre-computed cumulative alphas\n",
    "        alphas_cumprod_prev: Cumulative alphas at t-1\n",
    "        betas: Beta schedule\n",
    "        device: Compute device\n",
    "\n",
    "    Returns:\n",
    "        x_{t-1}: Denoised image\n",
    "\n",
    "    TODO: Implement reverse diffusion formula\n",
    "    1. Get alpha values for timestep t\n",
    "    2. Predict original image from x_t and predicted noise\n",
    "    3. Compute posterior mean using Bayes theorem\n",
    "    4. Add variance (stochastic sampling)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Your implementation here\n",
    "    # Get alpha_t and alpha_t_prev\n",
    "    # Compute posterior mean and variance\n",
    "    # Return denoised sample\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test stub (will work once implemented)\n",
    "print(\"reverse_diffusion_step defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784da64",
   "metadata": {},
   "source": [
    "## Section 4: Implement Linear and Cosine Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfef534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: Implement LinearSchedule\n",
    "class LinearSchedule:\n",
    "    \"\"\"Linear (uniform) timestep schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, num_train_timesteps=1000, num_inference_steps=50):\n",
    "        \"\"\"\n",
    "        Initialize linear timestep schedule.\n",
    "\n",
    "        TODO: Create linearly spaced timesteps from num_train_timesteps-1 to 0\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.timesteps)\n",
    "\n",
    "\n",
    "# TODO 4: Implement CosineSchedule\n",
    "class CosineSchedule:\n",
    "    \"\"\"Cosine (non-linear) timestep schedule focusing on high-noise steps.\"\"\"\n",
    "\n",
    "    def __init__(self, num_train_timesteps=1000, num_inference_steps=50):\n",
    "        \"\"\"\n",
    "        Initialize cosine timestep schedule.\n",
    "\n",
    "        TODO: Create non-linear timesteps using cosine formula\n",
    "        Formula: α_t = cos²(π * (t/N + s) / (1+s)) where s=0.008\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.timesteps)\n",
    "\n",
    "\n",
    "# Test schedule creation\n",
    "print(\"Schedule classes defined (TODOs to complete)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fcdf0",
   "metadata": {},
   "source": [
    "## Section 5: Implement Complete Sampling Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Implement sample_with_schedule\n",
    "def sample_with_schedule(\n",
    "    model, schedule_type, num_steps, batch_size, device, return_trajectory=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete sampling pipeline with chosen schedule.\n",
    "\n",
    "    Args:\n",
    "        model: U-Net model\n",
    "        schedule_type: \"linear\" or \"cosine\"\n",
    "        num_steps: Number of sampling steps\n",
    "        batch_size: Number of images to generate\n",
    "        device: Compute device\n",
    "        return_trajectory: Whether to save intermediate steps\n",
    "\n",
    "    Returns:\n",
    "        samples: Generated images (batch, 1, 28, 28)\n",
    "        trajectory: (optional) All intermediate steps\n",
    "\n",
    "    TODO: Implement complete sampling loop\n",
    "    1. Create schedule object (LinearSchedule or CosineSchedule)\n",
    "    2. Initialize with pure Gaussian noise\n",
    "    3. For each timestep:\n",
    "       a. Use model to predict noise\n",
    "       b. Call reverse_diffusion_step()\n",
    "       c. Save intermediate if needed\n",
    "    4. Return final samples\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Your implementation here\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"sample_with_schedule defined (TODO to complete)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f7904",
   "metadata": {},
   "source": [
    "## Section 6: Implement Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9afec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6: Implement compute_sample_variance\n",
    "def compute_sample_variance(samples):\n",
    "    \"\"\"\n",
    "    Measure diversity of generated samples.\n",
    "\n",
    "    Args:\n",
    "        samples: (batch, 1, 28, 28) tensor\n",
    "\n",
    "    Returns:\n",
    "        variance: Scalar indicating sample diversity\n",
    "\n",
    "    TODO: Flatten samples, compute mean across batch, then variance.\n",
    "    High variance = diverse samples (good)\n",
    "    Low variance = similar samples (mode collapse)\n",
    "    \"\"\"\n",
    "    # TODO: Your implementation here\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO 7: Implement compute_sharpness\n",
    "def compute_sharpness(samples):\n",
    "    \"\"\"\n",
    "    Estimate image clarity using Sobel edge detection.\n",
    "\n",
    "    Args:\n",
    "        samples: (batch, 1, 28, 28) tensor\n",
    "\n",
    "    Returns:\n",
    "        sharpness: Scalar indicating edge strength\n",
    "\n",
    "    TODO: Apply Sobel filters and compute average edge magnitude.\n",
    "    \"\"\"\n",
    "    # TODO: Your implementation here\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"Metric functions defined (TODOs to complete)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3a77a",
   "metadata": {},
   "source": [
    "## Section 7: Visualize Denoising Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 8: Use visualization helpers for comparison\n",
    "# After implementing sampling above, use these helpers:\n",
    "\n",
    "# 1. Compare final samples from both schedules\n",
    "plot_sample_comparison(linear_samples, cosine_samples, num_cols=4)\n",
    "\n",
    "# 2. Show denoising trajectory for each schedule\n",
    "plot_denoising_trajectory(\n",
    "    linear_trajectory, schedule_name=\"Linear Schedule\", num_steps=8\n",
    ")\n",
    "plot_denoising_trajectory(\n",
    "    cosine_trajectory, schedule_name=\"Cosine Schedule\", num_steps=8\n",
    ")\n",
    "\n",
    "# 3. Compare quality metrics\n",
    "linear_metrics = {\n",
    "    \"Variance\": linear_variance,\n",
    "    \"Sharpness\": linear_sharpness,\n",
    "    \"Mean\": linear_samples.mean().item(),\n",
    "}\n",
    "cosine_metrics = {\n",
    "    \"Variance\": cosine_variance,\n",
    "    \"Sharpness\": cosine_sharpness,\n",
    "    \"Mean\": cosine_samples.mean().item(),\n",
    "}\n",
    "plot_schedule_metrics(linear_metrics, cosine_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c53fbf07",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What You've Implemented\n",
    "\n",
    "In this notebook, you've built the complete reverse diffusion sampling pipeline:\n",
    "\n",
    "1. **LinearSchedule**: Uniform timestep spacing for fast generation\n",
    "2.  **CosineSchedule**: Non-linear spacing focusing on hard (high-noise) steps\n",
    "3.  **reverse_diffusion_step()**: Core algorithm for one denoising step\n",
    "4.  **sample_with_schedule()**: Complete sampling loop with trajectory tracking\n",
    "5.  **compute_sample_variance()**: Measure generation diversity\n",
    "6.  **compute_sharpness()**: Measure image clarity\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Linear schedule**: Fast but lower quality per step\n",
    "- **Cosine schedule**: Better quality with same computational cost\n",
    "- **Sampling schedule** is a design choice that doesn't change model complexity\n",
    "- **Quality-speed tradeoff** can be optimized through smart scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd90472",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
