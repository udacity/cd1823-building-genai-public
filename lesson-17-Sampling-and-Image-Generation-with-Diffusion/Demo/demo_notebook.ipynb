{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1de95c32",
   "metadata": {},
   "source": [
    "# Demo: Reverse Diffusion Sampling and Image Generation\n",
    "## Creating Images from Pure Noise with Fashion MNIST\n",
    "\n",
    "In this demo, we'll explore the complete reverse diffusion sampling process. Starting from pure Gaussian noise, we'll progressively denoise to create coherent Fashion MNIST images.\n",
    "\n",
    "**What You'll Learn:**\n",
    "- How reverse diffusion recovers images from noise\n",
    "- Comparing sampling schedules (linear vs cosine)\n",
    "- Visualizing the denoising trajectory\n",
    "- Understanding quality-speed tradeoffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67989b81",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import math\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\" Imports complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdbefce",
   "metadata": {},
   "source": [
    "## Section 2: Load Pre-trained Model and Noise Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize noise schedule (from training)\n",
    "num_timesteps = 1000\n",
    "betas = torch.linspace(0.0001, 0.02, num_timesteps, device=device)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alphas_cumprod_prev = torch.cat([torch.ones(1, device=device), alphas_cumprod[:-1]])\n",
    "\n",
    "print(f\"✓ Noise Schedule Configured:\")\n",
    "print(f\"  Total timesteps: {num_timesteps}\")\n",
    "print(f\"  Alpha range: [{alphas_cumprod[-1]:.6f}, {alphas_cumprod[0]:.6f}]\")\n",
    "\n",
    "\n",
    "# Load pre-trained U-Net model from Module 16\n",
    "# Create a simple placeholder model\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.enc2 = nn.Conv2d(64, 128, 3, padding=1, stride=2)\n",
    "        self.mid = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.dec = nn.ConvTranspose2d(128, 64, 4, padding=1, stride=2)\n",
    "        self.out = nn.Conv2d(64, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.mid(x))\n",
    "        x = F.relu(self.dec(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleUNet().to(device)\n",
    "model.eval()\n",
    "\n",
    "# Try to load checkpoint\n",
    "checkpoint_path = \"../../lesson-16-Implementing-Simple-Diffusion-Model/checkpoint.pt\"\n",
    "try:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint.get(\"model_state_dict\", checkpoint))\n",
    "    print(f\" Loaded pre-trained model\")\n",
    "except:\n",
    "    print(f\" Using untrained model (checkpoint not found)\")\n",
    "\n",
    "print(f\" Model ready on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e74aa",
   "metadata": {},
   "source": [
    "## Section 3: Implement Reverse Diffusion Core Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_diffusion_step(x_t, t, pred_noise):\n",
    "    \"\"\"Single reverse diffusion step: x_t → x_{t-1}\"\"\"\n",
    "    alpha_t = alphas_cumprod[t]\n",
    "    alpha_t_prev = alphas_cumprod_prev[t]\n",
    "    beta_t = betas[t]\n",
    "\n",
    "    # Predict original image\n",
    "    x_0_pred = (x_t - torch.sqrt(1 - alpha_t) * pred_noise) / torch.sqrt(alpha_t)\n",
    "\n",
    "    # Posterior mean\n",
    "    variance = (1 - alpha_t_prev) * beta_t / (1 - alpha_t)\n",
    "    coef1 = torch.sqrt(alpha_t_prev) * beta_t / (1 - alpha_t)\n",
    "    coef2 = (1 - beta_t) * torch.sqrt(1 - alpha_t_prev) / (1 - alpha_t)\n",
    "\n",
    "    mean = coef1 * x_0_pred + coef2 * x_t\n",
    "\n",
    "    # Add noise\n",
    "    if t > 0:\n",
    "        z = torch.randn_like(x_t)\n",
    "        x_t_minus_1 = mean + torch.sqrt(variance) * z\n",
    "    else:\n",
    "        x_t_minus_1 = mean\n",
    "\n",
    "    return x_t_minus_1\n",
    "\n",
    "\n",
    "print(\"✓ Reverse diffusion step implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6650ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSchedule:\n",
    "    \"\"\"Linear timestep schedule: uniform sampling across timesteps\"\"\"\n",
    "\n",
    "    def __init__(self, num_timesteps):\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "    def get_timesteps(self, num_steps):\n",
    "        \"\"\"Get linearly spaced timesteps\"\"\"\n",
    "        return torch.linspace(0, self.num_timesteps - 1, num_steps).long()\n",
    "\n",
    "\n",
    "class CosineSchedule:\n",
    "    \"\"\"Cosine timestep schedule: emphasize early/mid timesteps\"\"\"\n",
    "\n",
    "    def __init__(self, num_timesteps, s=0.008):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.s = s\n",
    "\n",
    "    def get_timesteps(self, num_steps):\n",
    "        \"\"\"Get cosine-weighted timesteps\"\"\"\n",
    "        steps = torch.linspace(0, 1, num_steps + 1)\n",
    "        alphas = torch.cos((steps + self.s) / (1 + self.s) * np.pi * 0.5) ** 2\n",
    "        alphas = alphas / alphas[0]\n",
    "        timesteps = (1 - alphas) * (self.num_timesteps - 1)\n",
    "        return torch.floor(timesteps[1:]).long()\n",
    "\n",
    "\n",
    "linear_schedule = LinearSchedule(num_timesteps)\n",
    "cosine_schedule = CosineSchedule(num_timesteps)\n",
    "\n",
    "print(\" Sampling schedules implemented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f996815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_schedule(num_samples, schedule, schedule_name):\n",
    "    \"\"\"Generate samples using specified timestep schedule\"\"\"\n",
    "    x_t = torch.randn(num_samples, 1, 28, 28, device=device)\n",
    "    timesteps = schedule.get_timesteps(50)  # 50 steps\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, t in enumerate(timesteps):\n",
    "            t_tensor = torch.full((num_samples,), t, dtype=torch.long, device=device)\n",
    "\n",
    "            # Predict noise\n",
    "            pred_noise = model(x_t, t_tensor.view(-1))\n",
    "\n",
    "            # Reverse step\n",
    "            x_t = reverse_diffusion_step(x_t, t.item(), pred_noise)\n",
    "\n",
    "    # Clip to valid range\n",
    "    x_t = torch.clamp(x_t, -1, 1)\n",
    "    return x_t\n",
    "\n",
    "\n",
    "# Generate samples with both schedules\n",
    "print(\"Generating samples...\")\n",
    "linear_samples = sample_with_schedule(16, linear_schedule, \"linear\")\n",
    "cosine_samples = sample_with_schedule(16, cosine_schedule, \"cosine\")\n",
    "print(\"✓ Samples generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_grid(samples, title, nrows=4, ncols=4):\n",
    "    \"\"\"Visualize sample grid\"\"\"\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(8, 8))\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < len(samples):\n",
    "            img = samples[idx].cpu().squeeze().numpy()\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_image_statistics(samples):\n",
    "    \"\"\"Compute mean and std of samples\"\"\"\n",
    "    flat = samples.reshape(samples.size(0), -1)\n",
    "    return {\n",
    "        \"mean\": flat.mean(dim=1).mean().item(),\n",
    "        \"std\": flat.std(dim=1).mean().item(),\n",
    "        \"min\": samples.min().item(),\n",
    "        \"max\": samples.max().item(),\n",
    "    }\n",
    "\n",
    "\n",
    "# Visualize both schedules\n",
    "plot_samples_grid(linear_samples, \"Linear Schedule (50 steps)\")\n",
    "plot_samples_grid(cosine_samples, \"Cosine Schedule (50 steps)\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nLinear Schedule Statistics:\")\n",
    "lin_stats = compute_image_statistics(linear_samples)\n",
    "for key, val in lin_stats.items():\n",
    "    print(f\"  {key}: {val:.4f}\")\n",
    "\n",
    "print(\"\\nCosine Schedule Statistics:\")\n",
    "cos_stats = compute_image_statistics(cosine_samples)\n",
    "for key, val in cos_stats.items():\n",
    "    print(f\"  {key}: {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8677df",
   "metadata": {},
   "source": [
    "## Section 4: Analysis and Key Insights\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Timestep Schedules Matter**: Different schedules (linear vs cosine) produce different quality outputs\n",
    "2. **Reverse Process**: Starting from pure noise, we iteratively denoise to generate realistic images\n",
    "3. **Conditioning**: Both schedules can be enhanced with class labels for conditional generation\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "- **Linear Schedule**: Uniform timestep coverage - predictable but may waste steps on low-noise regions\n",
    "- **Cosine Schedule**: Biased toward mid/early timesteps - more efficient allocation of denoising effort\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different numbers of sampling steps (10, 25, 50, 100)\n",
    "- Try varying schedules (exponential, polynomial)\n",
    "- Implement classifier-free guidance for better sample control\n",
    "- Combine with other techniques (VAE-augmented sampling, progressive refinement)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
