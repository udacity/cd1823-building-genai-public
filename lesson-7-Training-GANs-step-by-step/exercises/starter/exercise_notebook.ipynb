{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe6bbc3",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports\n",
    "\n",
    "First, let's import all necessary libraries and set up our training device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbf6d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setup complete. Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import training functions from gan_training module\n",
    "from models.gan_training import train_gan, visualize_losses, analyze_convergence\n",
    "from models.basic_gan import create_generator, create_discriminator\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Determine device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\" Setup complete. Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceedaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers \n",
    "def plot_training_losses(d_losses, g_losses):\n",
    "    \"\"\"Plot discriminator and generator losses during training.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot D loss\n",
    "    axes[0].plot(d_losses, linewidth=2, color=\"navy\", label=\"D Loss\")\n",
    "    axes[0].axhline(y=0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Ideal (0.5)\")\n",
    "    axes[0].axhline(\n",
    "        y=np.log(2), color=\"gray\", linestyle=\":\", alpha=0.5, label=\"Random (log2)\"\n",
    "    )\n",
    "    axes[0].set_xlabel(\"Batch\", fontsize=11)\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize=11)\n",
    "    axes[0].set_title(\"Discriminator Loss\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "    # Plot G loss\n",
    "    axes[1].plot(g_losses, linewidth=2, color=\"darkgreen\", label=\"G Loss\")\n",
    "    axes[1].set_xlabel(\"Batch\", fontsize=11)\n",
    "    axes[1].set_ylabel(\"Loss\", fontsize=11)\n",
    "    axes[1].set_title(\"Generator Loss\", fontsize=12, fontweight=\"bold\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sample_progression(generated_samples, checkpoint_intervals=5):\n",
    "    \"\"\"Display generated samples progression over training epochs.\"\"\"\n",
    "    num_checkpoints = len(generated_samples)\n",
    "    cols = min(6, num_checkpoints)\n",
    "    rows = (num_checkpoints + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 3.5 * rows))\n",
    "    axes = axes.flatten() if num_checkpoints > 1 else [axes]\n",
    "\n",
    "    for checkpoint_idx, samples in enumerate(generated_samples):\n",
    "        epoch_num = (checkpoint_idx + 1) * checkpoint_intervals\n",
    "        ax = axes[checkpoint_idx]\n",
    "\n",
    "        # Handle both grid tensors and batch tensors\n",
    "        if len(samples.shape) == 4:\n",
    "            # Batch of samples - make a grid\n",
    "            grid_img = torchvision.utils.make_grid(samples, nrow=4, normalize=True)\n",
    "            grid_np = grid_img.squeeze().cpu().detach().numpy()\n",
    "        else:\n",
    "            # Already a grid\n",
    "            grid_np = samples.squeeze().cpu().detach().numpy()\n",
    "\n",
    "        if grid_np.ndim == 3 and grid_np.shape[0] == 3:\n",
    "            grid_np = np.transpose(grid_np, (1, 2, 0))\n",
    "            ax.imshow(grid_np)\n",
    "        else:\n",
    "            ax.imshow(grid_np, cmap=\"gray\")\n",
    "\n",
    "        ax.set_title(f\"Epoch {epoch_num}\", fontsize=10, fontweight=\"bold\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(checkpoint_idx + 1, len(axes)):\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Generated Samples Over Training\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\" Visualization helpers loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b7905",
   "metadata": {},
   "source": [
    "## Part 2: Load Fashion MNIST Dataset\n",
    "\n",
    "### Task\n",
    "TODO: Create data transforms and DataLoader for Fashion MNIST.\n",
    "\n",
    "**Requirements:**\n",
    "- Normalize images to [-1, 1] range (important for GAN training!)\n",
    "- Batch size = 64\n",
    "- Shuffle = True\n",
    "\n",
    "**Hint:** Use `transforms.Compose()` to chain ToTensor and Normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (0.5,)),\n",
    "# ])\n",
    "\n",
    "# TODO: Load Fashion MNIST training dataset\n",
    "# train_dataset = datasets.FashionMNIST(\n",
    "#     root='./data',\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=transform\n",
    "# )\n",
    "\n",
    "# TODO: Create DataLoader\n",
    "batch_size = 64\n",
    "# train_loader = DataLoader(...)\n",
    "\n",
    "print(f\"Total images: {len(train_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0e6e7",
   "metadata": {},
   "source": [
    "### Verification: Check Data Shape\n",
    "\n",
    "Run this cell to verify your data loading is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: Get a sample batch\n",
    "sample_batch, sample_labels = next(iter(train_loader))\n",
    "print(f\"Sample batch shape: {sample_batch.shape}\")\n",
    "print(f\"  Expected: torch.Size([64, 1, 28, 28])\")\n",
    "print(f\"Sample labels shape: {sample_labels.shape}\")\n",
    "print(f\"  Expected: torch.Size([64])\")\n",
    "\n",
    "# Check value range\n",
    "print(f\"\\nImage values in range: [{sample_batch.min():.2f}, {sample_batch.max():.2f}]\")\n",
    "print(f\"  Expected: [-1.0, 1.0]\")\n",
    "\n",
    "if (\n",
    "    sample_batch.shape == torch.Size([64, 1, 28, 28])\n",
    "    and -1.1 < sample_batch.min() < -0.9\n",
    "    and 0.9 < sample_batch.max() < 1.1\n",
    "):\n",
    "    print(\"\\n Data loading correct!\")\n",
    "else:\n",
    "    print(\"\\n Data loading has issues. Check the TODO section above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58a487",
   "metadata": {},
   "source": [
    "## Part 3: Visualize Sample Images\n",
    "\n",
    "Let's look at some real Fashion MNIST images to understand what we're generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f53685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 8 random samples from Fashion MNIST\n",
    "fig, axes = plt.subplots(1, 8, figsize=(12, 2))\n",
    "\n",
    "for i in range(8):\n",
    "    ax = axes[i]\n",
    "    img = sample_batch[i].squeeze().numpy()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Sample Real Images from Fashion MNIST\", fontsize=12, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These are the types of images the GAN needs to learn to generate!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd7565",
   "metadata": {},
   "source": [
    "## Part 4: Create Generator and Discriminator\n",
    "\n",
    "### Task\n",
    "TODO: Create the generator and discriminator models using functions from previous lessons.\n",
    "\n",
    "**Requirements:**\n",
    "- Use `create_generator()` with latent_dim=100\n",
    "- Use `create_discriminator()`\n",
    "- Move both to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create generator\n",
    "latent_dim = 100\n",
    "# generator = create_generator(...)\n",
    "\n",
    "# TODO: Create discriminator\n",
    "# discriminator = create_discriminator()\n",
    "\n",
    "# TODO: Move to device\n",
    "# generator = generator.to(device)\n",
    "# discriminator = discriminator.to(device)\n",
    "\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(\n",
    "    f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0c236e2",
   "metadata": {},
   "source": [
    "## Part 5: Train the GAN\n",
    "\n",
    "### Task\n",
    "TODO: Call `train_gan()` to train both networks for 50 epochs.\n",
    "\n",
    "**Requirements:**\n",
    "- num_epochs = 50\n",
    "- learning_rate = 0.0002\n",
    "- beta1 = 0.5\n",
    "- checkpoint_interval = 5\n",
    "- verbose = True (to see progress)\n",
    "\n",
    "**Note:** This will take 5-10 minutes depending on your device. \n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "Epoch [1/50], Batch [N/M]\n",
    "  D Loss: 0.6823 | G Loss: 0.8901 | Running D Avg: 0.6234\n",
    "...\n",
    "Training complete!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting GAN training...\")\n",
    "print(\"(This will take 5-10 minutes depending on your device)\\n\")\n",
    "\n",
    "# TODO: Call train_gan() with appropriate parameters\n",
    "# d_losses, g_losses, generated_samples = train_gan(\n",
    "#     generator=generator,\n",
    "#     discriminator=discriminator,\n",
    "#     train_loader=train_loader,\n",
    "#     num_epochs=50,\n",
    "#     device=device,\n",
    "#     learning_rate=0.0002,\n",
    "#     beta1=0.5,\n",
    "#     checkpoint_interval=5,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "print(\"\\n Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdd116",
   "metadata": {},
   "source": [
    "## Part 6: Analyze Loss Curves\n",
    "\n",
    "### Task\n",
    "TODO: Visualize discriminator and generator losses over time.\n",
    "\n",
    "**What to Look For:**\n",
    "- **D loss**: Should stabilize around 0.5-0.7 (balanced with G)\n",
    "- **G loss**: Should decrease over time (learning to fool D)\n",
    "- **Baseline**: Horizontal line at 0.693 (log(2), random guessing)\n",
    "\n",
    "**Failure Modes:**\n",
    "- ✗ D loss → 0: Generator collapsed (mode collapse)\n",
    "- ✗ D loss → 1: Discriminator too good, G can't learn\n",
    "- ✗ Wild oscillations: Unstable training\n",
    "- ✓ Both curves smooth and stable: Training worked!\n",
    "\n",
    "**Hint:** Use `visualize_losses()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c90d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualizing loss curves...\\n\")\n",
    "\n",
    "# TODO: Call visualize_losses() and display\n",
    "# fig = visualize_losses(d_losses, g_losses)\n",
    "# plt.show()\n",
    "\n",
    "print(\"\\nObservations from loss curves:\")\n",
    "print(f\"  Discriminator - Initial: {d_losses[0]:.4f}, Final: {d_losses[-1]:.4f}\")\n",
    "print(f\"  Generator - Initial: {g_losses[0]:.4f}, Final: {g_losses[-1]:.4f}\")\n",
    "print(f\"  D Loss Range: [{min(d_losses):.4f}, {max(d_losses):.4f}]\")\n",
    "print(f\"  G Loss Range: [{min(g_losses):.4f}, {max(g_losses):.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63c887",
   "metadata": {},
   "source": [
    "## Part 7: Detailed Loss Statistics\n",
    "\n",
    "### Analysis\n",
    "Print detailed statistics about the losses to understand training dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3648149",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LOSS STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nDiscriminator Loss:\")\n",
    "print(f\"  Initial: {d_losses[0]:.4f}\")\n",
    "print(f\"  Final: {d_losses[-1]:.4f}\")\n",
    "print(f\"  Min: {min(d_losses):.4f}\")\n",
    "print(f\"  Max: {max(d_losses):.4f}\")\n",
    "print(f\"  Average: {np.mean(d_losses):.4f}\")\n",
    "print(f\"  Std Dev: {np.std(d_losses):.4f}\")\n",
    "\n",
    "print(\"\\nGenerator Loss:\")\n",
    "print(f\"  Initial: {g_losses[0]:.4f}\")\n",
    "print(f\"  Final: {g_losses[-1]:.4f}\")\n",
    "print(f\"  Min: {min(g_losses):.4f}\")\n",
    "print(f\"  Max: {max(g_losses):.4f}\")\n",
    "print(f\"  Average: {np.mean(g_losses):.4f}\")\n",
    "print(f\"  Std Dev: {np.std(g_losses):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823ef91",
   "metadata": {},
   "source": [
    "## Part 8: Convergence Analysis\n",
    "\n",
    "### Task\n",
    "TODO: Use `analyze_convergence()` to detect failure modes and Nash Equilibrium.\n",
    "\n",
    "**What It Checks:**\n",
    "- Is D loss too low? (Mode collapse)\n",
    "- Is D loss too high? (G can't learn)\n",
    "- Are losses stable?\n",
    "- Did both networks reach equilibrium?\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "Recent 100 batches analysis:\n",
    "  D Loss: avg=0.52, std=0.08 → STABLE\n",
    "  G Loss: avg=0.89, std=0.12 → STABLE\n",
    "  \n",
    "Assessment:\n",
    "  ✓ Discriminator performance: BALANCED\n",
    "  ✓ Generator learning: IMPROVING\n",
    "  ✓ Overall: LIKELY NASH EQUILIBRIUM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONVERGENCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Call analyze_convergence()\n",
    "# analyze_convergence(d_losses, g_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf461c",
   "metadata": {},
   "source": [
    "## Part 9: Visualize Generated Samples\n",
    "\n",
    "### Task\n",
    "TODO: Display generated samples from each checkpoint to see how quality improves over training.\n",
    "\n",
    "**Expected Progression:**\n",
    "- Epoch 5: Random noise-like patterns\n",
    "- Epoch 10-15: Blurry shapes forming\n",
    "- Epoch 20-30: Recognizable clothing items\n",
    "- Epoch 40-50: Clear, detailed Fashion MNIST clothing\n",
    "\n",
    "**Hint:** Loop through `generated_samples` list. Each item is a grid tensor from that epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10646aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualizing generated samples over training...\\n\")\n",
    "\n",
    "\n",
    "# Display sample progression using helper\n",
    "plot_sample_progression(generated_samples, checkpoint_intervals=5)\n",
    "\n",
    "print(\"✓ Sample visualization complete\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13fd7903",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **GAN Training is an Adversarial Game**\n",
    "   - D learns to classify real vs fake\n",
    "   - G learns to fool D\n",
    "   - Both compete for equilibrium\n",
    "\n",
    "2. **Loss Curves Tell the Story**\n",
    "   - Good: Both losses stabilize\n",
    "   - Bad: D loss → 0 (mode collapse) or → 1 (D too strong)\n",
    "   - Ideal: D loss around 0.5-0.7, G loss decreasing\n",
    "\n",
    "3. **Nash Equilibrium in GANs**\n",
    "   - Both networks reach stable performance point\n",
    "   - Neither can improve further without making opponent worse\n",
    "   - Indicates successful convergence\n",
    "\n",
    "4. **Sample Quality Improves Over Time**\n",
    "   - Early epochs: Random noise\n",
    "   - Middle epochs: Emerging patterns\n",
    "   - Late epochs: Clear, recognizable clothing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eaf81a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "36371cb60c26e37b7d9a2ceed614c6abe3cd2e9c2c4d621fd25f98fd923082ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
